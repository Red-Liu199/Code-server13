INFO:root:Added special tokens to gpt tokenizer.
INFO:root:Reading encoded data from ./data/multi-woz-2.1-processed/new_db_se_blank_encoded.data.json
INFO:root:Added special tokens to gpt tokenizer.
INFO:root:Reading encoded data from ./data/multi-woz-2.1-processed/new_db_se_blank_encoded.data.json
INFO:root:train size:8434, dev size:999, test size:1000
INFO:root:Dialogs per rl epoch:1000
INFO:root:Reward example. BS reward:[1, 1.0, 1.0, 1.0], Act reward:[1.0, 1.0, -1.0, 1.0], Resp reward:[1, 1, 1, 1], Session reward:0
INFO:root:Reward example. BS reward:[1.0, 1.0, 0.33333333333333326, 0.33333333333333326], Act reward:[-1.0, 0.0, 0.0, 1.0], Resp reward:[1, -1, 1, 1], Session reward:0.0
INFO:root:Reward example. BS reward:[1.0, 1.0, 1.0, 0.5], Act reward:[-1.0, 1.0, -1.0, -1.0], Resp reward:[1, -1, 1, -1], Session reward:0
INFO:root:Reward example. BS reward:[1, 1, 1, 1], Act reward:[1, 1.0, -1.0, 1.0], Resp reward:[1, 1, 1, 1], Session reward:1.0
INFO:root:Example rewards of one batch :[[(1, 1.0, 1), (1.0, 1.0, 1), (1.0, -1.0, 1), (1.0, 1.0, 1)], [(1.0, -1.0, 1.0), (1.0, 0.0, -1.0), (0.33333333333333326, 0.0, 1.0), (0.33333333333333326, 1.0, 1.0)], [(1.0, -1.0, 1), (1.0, 1.0, -1), (1.0, -1.0, 1), (0.5, -1.0, -1)], [(2.0, 2.0, 2.0), (2.0, 2.0, 2.0), (2.0, 0.0, 2.0), (2.0, 2.0, 2.0)]]
INFO:root:Reward example. BS reward:[1.0, 0.33333333333333326, 1.0, 1.0], Act reward:[-1.0, -1.0, 1.0, 1.0], Resp reward:[1, 1, 1, 1], Session reward:1.0
INFO:root:Reward example. BS reward:[1.0, 1.0, 1.0, 1.0], Act reward:[0.0, 0.0, 0.0, 1.0], Resp reward:[1, 1, 1, 1], Session reward:1.0
INFO:root:Reward example. BS reward:[1.0, 1.0, 1.0, 1.0], Act reward:[1.0, -0.33333333333333337, 0.33333333333333326, -1.0], Resp reward:[1, 1, 1, 1], Session reward:0.5
INFO:root:Reward example. BS reward:[1.0, 0.33333333333333326, 0.33333333333333326, 0.33333333333333326], Act reward:[-1.0, -0.33333333333333337, 1.0, 1.0], Resp reward:[-1, 1, 1, 1], Session reward:1.0
INFO:root:Example rewards of one batch :[[(2.0, 0.0, 2.0), (1.3333333333333333, 0.0, 2.0), (2.0, 2.0, 2.0), (2.0, 2.0, 2.0)], [(2.0, 1.0, 2.0), (2.0, 1.0, 2.0), (2.0, 1.0, 2.0), (2.0, 2.0, 2.0)], [(1.5, 1.5, 1.5), (1.5, 0.16666666666666663, 1.5), (1.5, 0.8333333333333333, 1.5), (1.5, -0.5, 1.5)], [(2.0, 0.0, 0.0), (1.3333333333333333, 0.6666666666666666, 2.0), (1.3333333333333333, 2.0, 2.0), (1.3333333333333333, 2.0, 2.0)]]
INFO:root:Epoch:0, time:3.101 min
INFO:root:Inference time:5.766561
INFO:root:Dev reward:(8170.605046260933, 3664.502380952384, 10264.499999999998), metrics:(67.53507014027379, 49.09819639278065, 11.505508219495471, 69.82214148602269)
INFO:root:Average reward of epoch 0: 9.776799269842698
INFO:root:Epoch:1, time:2.839 min
INFO:root:Inference time:5.748873
INFO:root:Dev reward:(8110.7339410589475, 3640.7039682539726, 10211.499999999998), metrics:(69.73947895790884, 51.20240480961411, 11.628975995161719, 72.0999178789232)
INFO:root:Average reward of epoch 1: 8.709736162275226
INFO:root:Epoch:2, time:4.156 min
INFO:root:Inference time:5.756491
INFO:root:Dev reward:(8236.981379731385, 3737.604761904766, 10249.666666666664), metrics:(67.63527054107539, 48.19639278556631, 11.658683224504125, 69.57451488782498)
INFO:root:Average reward of epoch 2: 11.600722869253145
INFO:root:Epoch:3, time:2.942 min
INFO:root:Inference time:5.842286
INFO:root:Dev reward:(8290.925196861966, 3804.1277777777777, 10236.666666666664), metrics:(70.2404809619168, 50.601202404804546, 11.347172814787477, 71.76801449814815)
INFO:root:Average reward of epoch 3: 9.452841071369907
INFO:root:Epoch:4, time:3.681 min
